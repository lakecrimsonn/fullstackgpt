{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# langchain, llm과 친해지기\n",
    "## 기본적인 사용방법\n",
    "- OpenAI()의 text-davinci-003보다는 gpt-3.5-turbo가 비용적인 면이나, 최신 데이터를 사용하는 면에서 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\\n\\nThere are 8 planets in the Solar System: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.',\n",
       " 'As of now, there are eight recognized planets in our solar system: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = OpenAI()\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "a = llm.predict(\"How many planets are there?\")\n",
    "b = chat.predict(\"How many planets are there?\")\n",
    "\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## messages 이용하기\n",
    "- 구체적으로 질문하고 대답을 받을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "chat = ChatOpenAI(temperature=0.1) # temperature 0.1은 덜 창의적으로 대답한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a geography expert. Any you only reply in Korean.\"),\n",
    "    AIMessage(content=\"안녕하세요. 똥꾸빵꾸입니다.\"),\n",
    "    HumanMessage(content=\"What is the distance between Mexico and Thailand. Also, what is your name?\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요! 저는 똥꾸빵꾸라고 합니다. 멕시코와 태국 사이의 거리는 대략 17,000 킬로미터입니다.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.predict_messages(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prompt templates\n",
    "- 템플릿은 자주 사용되는 프롬프트를 커스터마이징하면서 재사용할 수 있다.\n",
    "- PromptTemplate은 스트링 기반, ChatPromptTemplate은 메세지 기반이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The distance between Mexico and Thailand is approximately 16,000 kilometers (9,942 miles).'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "template = PromptTemplate.from_template(\n",
    "    \"What is the distance between {country_a} and {country_b}\"\n",
    ")\n",
    "\n",
    "prompt = template.format(country_a=\"Mexico\", country_b=\"Thailand\")\n",
    "\n",
    "chat.predict(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요. 저의 이름은 홍길동입니다. 멕시코와 태국 사이의 거리는 대략 17,000 킬로미터입니다.')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a geography expert. Any you only reply in {language}.\"),\n",
    "    (\"ai\", \"안녕하세요. 저의 이름은 {name}.\"),\n",
    "    (\"human\", \"What is the distance between {country_a} and {country_b}. Also, what is your name?\")\n",
    "])\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    language=\"Korean\",\n",
    "    name=\"홍길동\",\n",
    "    country_a=\"Mexico\",\n",
    "    country_b=\"Thailand\"\n",
    ")\n",
    "\n",
    "chat.predict_messages(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## output parser\n",
    "\n",
    "- 디비나 다른 곳으로 텍스트를 저장할 때, 기존의 형태가 아닌 다른 형태로 저장하고 싶을 때 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'how', 'are', 'you']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "# 공백을 지우고, 콤마를 기준으로 잘라서 리스트에 담는다.\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    def parse(self, text):\n",
    "        items = text.strip().split(\",\")\n",
    "        return list(map(str.strip, items))\n",
    "\n",
    "p = CommaOutputParser()\n",
    "p.parse(\"hello, how, are, you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red',\n",
       " 'orange',\n",
       " 'yellow',\n",
       " 'green',\n",
       " 'blue',\n",
       " 'indigo',\n",
       " 'violet',\n",
       " 'black',\n",
       " 'white',\n",
       " 'gray']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a list generating machine. Everything you are asked will be answered with a comma seperated list of max {max_items} in lowercase. Do not reply with anything else.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    max_items=10,\n",
    "    question=\"What are the colors?\"\n",
    ")\n",
    "\n",
    "result = chat.predict_messages(prompt)\n",
    "\n",
    "p = CommaOutputParser()\n",
    "p.parse(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lcel\n",
    "- Langchain expression language\n",
    "- 랭체인은 내부적으로 template.format_messages를 호출하고, chat.predict를 호출하고, parse를 호출한다.\n",
    "- 사용설명서 : https://python.langchain.com/docs/expression_language/interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pikachu', 'charizard', 'bulbasaur', 'squirtle', 'jigglypuff']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 템플릿, 모델, 파서를 체인으로 묶는다.\n",
    "chain = template | chat | CommaOutputParser()\n",
    "chain.invoke({\n",
    "    \"max_items\":5,\n",
    "    \"question\":\"What are the pokemons?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chaining chains\n",
    "- all = 체인1 | 체인2 | 아웃풋\n",
    "- 체인끼리 묶는 것 역시 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for ChatOpenAI\ncallbacks -> 0\n  instance of BaseCallbackHandler expected (type=type_error.arbitrary_type; expected_arbitrary_type=BaseCallbackHandler)\ncallbacks\n  instance of BaseCallbackManager expected (type=type_error.arbitrary_type; expected_arbitrary_type=BaseCallbackManager)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StreamingStdOutCallbackHandler\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 스트리밍과 콜백을 지정해주면 진행상황을 알 수 있다.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m chat \u001b[38;5;241m=\u001b[39m \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstreaming\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mStreamingStdOutCallbackHandler\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m chef_prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages([\n\u001b[0;32m      9\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a world-class international chef. You create easy to follow recipies for any type of cuisine with easy to find ingredients.\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     10\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI want to cook \u001b[39m\u001b[38;5;132;01m{cusine}\u001b[39;00m\u001b[38;5;124m food.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m ])\n\u001b[0;32m     13\u001b[0m chef_chain \u001b[38;5;241m=\u001b[39m chef_prompt \u001b[38;5;241m|\u001b[39m chat\n",
      "File \u001b[1;32mc:\\Users\\koosj\\gptapps\\fullstack-gpt\\env\\lib\\site-packages\\langchain\\load\\serializable.py:97\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 97\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32mc:\\Users\\koosj\\gptapps\\fullstack-gpt\\env\\lib\\site-packages\\pydantic\\main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: 2 validation errors for ChatOpenAI\ncallbacks -> 0\n  instance of BaseCallbackHandler expected (type=type_error.arbitrary_type; expected_arbitrary_type=BaseCallbackHandler)\ncallbacks\n  instance of BaseCallbackManager expected (type=type_error.arbitrary_type; expected_arbitrary_type=BaseCallbackManager)"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "# 스트리밍과 콜백을 지정해주면 진행상황을 알 수 있다.\n",
    "chat = ChatOpenAI(temperature=0.1, streaming=True, callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "chef_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world-class international chef. You create easy to follow recipies for any type of cuisine with easy to find ingredients.\"),\n",
    "    (\"human\", \"I want to cook {cusine} food.\")\n",
    "])\n",
    "\n",
    "chef_chain = chef_prompt | chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "veg_chef_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a vegetarian chef specialized on making traditional recipies vegetarian. You find alternative ingredients and explain their preparation. You don't radically modify the recipe. If there is no alternative for a food just say you don't know how to replace it.\"),\n",
    "    (\"human\", \"{recipe}\")\n",
    "])\n",
    "\n",
    "veg_chain = veg_chef_prompt | chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"To make a vegetarian version of Butter Chicken, you can replace the chicken with a plant-based protein such as tofu or paneer. Here's how you can modify the recipe:\\n\\nIngredients:\\n- 500g tofu or paneer, cut into bite-sized pieces\\n- 2 tablespoons butter (or vegan butter for a vegan version)\\n- 1 onion, finely chopped\\n- 2 cloves of garlic, minced\\n- 1-inch piece of ginger, grated\\n- 2 teaspoons garam masala\\n- 1 teaspoon turmeric powder\\n- 1 teaspoon chili powder (adjust according to your spice preference)\\n- 1 cup tomato puree\\n- 1/2 cup heavy cream (or coconut cream for a vegan version)\\n- Salt, to taste\\n- Fresh cilantro leaves, for garnish\\n\\nInstructions:\\n1. Heat the butter in a large pan over medium heat. Add the chopped onion and sauté until it turns golden brown.\\n2. Add the minced garlic and grated ginger to the pan. Cook for another minute until fragrant.\\n3. In a small bowl, mix together the garam masala, turmeric powder, and chili powder. Add this spice mixture to the pan and cook for a minute, stirring continuously.\\n4. Add the tofu or paneer pieces to the pan and cook until they are lightly browned on all sides.\\n5. Pour in the tomato puree and season with salt. Stir well to combine all the ingredients.\\n6. Reduce the heat to low, cover the pan, and let the tofu or paneer simmer for about 15-20 minutes, or until it absorbs the flavors and becomes tender.\\n7. Stir in the heavy cream (or coconut cream) and cook for an additional 2-3 minutes to allow the flavors to meld together.\\n8. Taste and adjust the seasoning if needed.\\n9. Garnish with fresh cilantro leaves before serving.\\n10. Serve the vegetarian Butter Chicken hot with steamed rice or naan bread.\\n\\nEnjoy your vegetarian version of Butter Chicken!\")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain = {\"recipe\": chef_chain} | veg_chain\n",
    "\n",
    "final_chain.invoke({\n",
    "    \"cusine\": \"indian\"\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
